{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["El modelo logit es una t√©cnica de regresi√≥n que se utiliza para predecir variables binarias, es decir, aquellas que solo pueden tomar dos valores, como quiebra (1) o no quiebra (0) en este caso. La ecuaci√≥n fundamental del modelo es:  \n"],"metadata":{"id":"ZAWeHnIHXkCu"}},{"cell_type":"markdown","source":["Ecuaci√≥n logit:"],"metadata":{"id":"T8e8Zme-skHd"}},{"cell_type":"code","source":[],"metadata":{"id":"nVrsV34zXy7F","executionInfo":{"status":"ok","timestamp":1756870952046,"user_tz":300,"elapsed":14,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Librerias e importaciones**"],"metadata":{"id":"wgcyTBnEYEtl"}},{"cell_type":"code","source":["# ================================================================\n","#  Librer√≠as e importaciones\n","# ================================================================\n","!pip install -q numpy pandas scikit-learn matplotlib seaborn\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n","from sklearn.metrics import (\n","    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",")\n","\n","sns.set(style=\"whitegrid\", rc={\"axes.spines.right\": False, \"axes.spines.top\": False})\n","plt.rcParams[\"figure.dpi\"] = 120\n"],"metadata":{"id":"JjgVMmGbYH5V","executionInfo":{"status":"ok","timestamp":1756870974641,"user_tz":300,"elapsed":22590,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# CARGAR DE DATOS"],"metadata":{"id":"UflCYXc5y4I7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"mEIUDypKar8h","executionInfo":{"status":"error","timestamp":1756871096192,"user_tz":300,"elapsed":121548,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}},"outputId":"b82af477-a94d-48d9-b943-4038898a6d5b"},"execution_count":2,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-907070862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}]},{"cell_type":"code","source":["#Comenzamos importando el modulo de Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Procedemos a cargar la base y cargamos informaci√≥n b√°sica sobre esta para verificar que sirva correctamente:\n","\n","\"\"\"\n","DATASET: American Bankruptcy Data\n","Link: https://www.kaggle.com/datasets/utkarshx27/american-companies-bankruptcy-prediction-dataset?resource=download\n","\n","Descripci√≥n: Contiene indicadores financieros de empresas en Estados Unidos,\n","a una variable que ind√≠ca si la empresa se quebr√≥ o no. Esta base es un panel de\n","datos entre 1999 y 2018.\n","\n","Variables principales:\n","- company_name: Identifica a cada empresa\n","- status_label: Determina si la empresa sigue operando (alive,failed)\n","- year: A√±o de la observaci√≥n\n","- current_assets: Activos corrientes\n","- total_assets: Activos totales\n","- total_long_term_debt: Deuda a largo plazo\n","- ebit: Ganancias antes de impuestos\n","- gross_profit: Beneficios brutos\n","- total_current_liabilities: Pasivo corriente total\n","- retained_earnings: Ganancias retenidas\n","- total_revenue: Ingresos totales\n","- total_liabilities: Pasivo total\n","- total_operating_expenses: Gastos operativos totales\n","- cost_of_goods_sold: Costo de los bienes vendidos\n","- depreciation_amortization: Depreciaci√≥n y amortizaci√≥n\n","- ebitda: Beneficios antes de impuestos y depreciaci√≥n y amortizaci√≥n\n","- inventory: Inventario total\n","- net_income: Ingresos netos\n","- total_receivables: Recibables totales\n","- market_value: Valor de mercado\n","- net_sales: Ventas brutas\n","\n","Total de registros disponibles = 78,682\n","\"\"\"\n","## Carga\n","df_empresas = pd.read_csv\\\n"," ('/content/drive/MyDrive/HE2 IA parcial 1/data/american_bankruptcy_renamed.csv')\n","\n","print(\"Informaci√≥n del dataset cargado:\")\n","print(f\"Dimensiones: {df_empresas.shape}\")\n","print(f\"Columnas: {list(df_empresas.columns)}\")\n","print(\"\\nDistribuci√≥n de la variable objetivo:\")\n"],"metadata":{"id":"fjjOelE7cOaR","executionInfo":{"status":"aborted","timestamp":1756871096253,"user_tz":300,"elapsed":66,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EdjkBHP-aqaP","executionInfo":{"status":"aborted","timestamp":1756871096256,"user_tz":300,"elapsed":67,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Procesamiento de datos\n","\n","No se realiz√≥ estandarizaci√≥n de las variables predictoras, ya que el conjunto de datos contiene √∫nicamente variables num√©ricas y los modelos log√≠sticos convergieron de manera estable. Adem√°s, se busc√≥ mantener comparabilidad con otros experimentos realizados"],"metadata":{"id":"xvimSJQpd2YV"}},{"cell_type":"code","source":["#Primero vemos si la base de datos esta balanceado alredor de nuestra varaible objetivo\n","\n","# Si existe la columna 'status_label' (alive/failed), convertirla a binaria:\n","if 'status_label' in df_empresas.columns:\n","    df_empresas['Bankruptcy'] = (\n","        df_empresas['status_label'].str.lower() == 'failed'\n","    ).astype(int)\n","\n","# Mostrar distribuci√≥n de la variable objetivo (0 = viva, 1 = quebrada)\n","print(\"\\nDistribuci√≥n de la variable objetivo (Bankruptcy):\")\n","print(df_empresas['Bankruptcy'].value_counts(normalize=True))"],"metadata":{"id":"BiHEDwb9YXyY","executionInfo":{"status":"aborted","timestamp":1756871096257,"user_tz":300,"elapsed":67,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================================================\n","#  ELIMINACI√ìN DE VARIABLES NO RELEVANTES\n","# ================================================================\n","# - 'company_name' -> identificador, no aporta a la predicci√≥n\n","# - 'year' -> solo se usar√° para dividir train/test, no como predictor\n","# - 'status_label' -> texto redundante de la variable objetivo\n","# ================================================================\n","\n","X = df_empresas.drop(columns=['company_name', 'year', 'status_label', 'Bankruptcy'],\n","                     errors='ignore')\n","y = df_empresas['Bankruptcy']\n","\n","print(\"\\nVariables predictoras (X):\")\n","print(list(X.columns)[:10], \" ... total:\", len(X.columns))\n"],"metadata":{"id":"sBVhLvqheess","executionInfo":{"status":"aborted","timestamp":1756871096257,"user_tz":300,"elapsed":67,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================================================================\n","#  DIVSION DE DATOS\n","# ================================================================\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Dividir en 70% train y 30% test (puedes ajustar test_size)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.3,        # 70%/30% split\n","    stratify=y,           # mantener proporci√≥n de clases\n","    random_state=42       # semilla para reproducibilidad\n",")\n","\n","print(f\"Tama√±o de entrenamiento: {X_train.shape[0]} filas\")\n","print(f\"Tama√±o de prueba: {X_test.shape[0]} filas\")\n","\n","print(\"\\nDistribuci√≥n en TRAIN:\")\n","print(y_train.value_counts(normalize=True))\n","\n","print(\"\\nDistribuci√≥n en TEST:\")\n","print(y_test.value_counts(normalize=True))\n"],"metadata":{"id":"usrk1X5dfG3k","executionInfo":{"status":"aborted","timestamp":1756871096265,"user_tz":300,"elapsed":74,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modelacion\n","Despu√©s de procesar los datos y dividir el conjunto en entrenamiento y prueba con un split aleatorio y estratificado (random_state=42), desarrollamos y evaluamos tres modelos de regresi√≥n log√≠stica:\n","\n","Logit b√°sico\n","\n","Logit Ridge (L2).\n","\n","Logit Lasso (L1)"],"metadata":{"id":"yWSytL1TgMDP"}},{"cell_type":"code","source":["# ================================================================\n","#DEFINICI√ìN DE MODELOS: Logit, Ridge y Lasso\n","# ---------------------------------------------------------------\n","# - Usamos scikit-learn LogisticRegression en tres variantes:\n","#   * Logit_Basico  -> sin regularizaci√≥n expl√≠cita (penalty='none')\n","#   * Logit_Ridge   -> regularizaci√≥n L2 (penalty='l2'), controla magnitud de coeficientes\n","#   * Logit_Lasso   -> regularizaci√≥n L1 (penalty='l1'), puede llevar coeficientes exactos a cero\n","# - max_iter alto para asegurar convergencia\n","# ================================================================\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","base_models = {\n","    \"Logit_Basico\": LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=5000),\n","    \"Logit_Ridge\":  LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=5000),\n","    \"Logit_Lasso\":  LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=5000),\n","}\n","\n"],"metadata":{"id":"V64IKUjIgQJc","executionInfo":{"status":"aborted","timestamp":1756871096266,"user_tz":300,"elapsed":0,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Elecci√≥n de hiperpar√°metros**\n","\n","\n","los modelos de regresi√≥n log√≠stica cuentan con hiperpar√°metros, que son valores que no se ajustan autom√°ticamente durante el entrenamiento, sino que debemos definir previamente. El m√°s importante es el par√°metro C = 1/Œª, que controla la intensidad de la regularizaci√≥n: valores bajos de C aplican m√°s regularizaci√≥n y simplifican el modelo, mientras que valores altos reducen la regularizaci√≥n y permiten un ajuste m√°s complejo.Este proceso prueba distintos valores de C y eval√∫a su desempe√±o usando el F1-score como m√©trica principal, ya que este indicador equilibra la precisi√≥n y el recall, lo cual es especialmente √∫til en nuestro caso debido al desbalance de clases (muy pocas empresas quiebran en comparaci√≥n con las que no). Finalmente, el valor de C que maximiza el F1-score se utiliza para reentrenar el modelo completo sobre el conjunto de entrenamiento, asegurando que el modelo final est√© optimizado para el objetivo de detectar quiebras con la mayor eficacia posible.\n","\n"],"metadata":{"id":"8zSEjZdNtX3x"}},{"cell_type":"code","source":["\n","# ================================================================\n","# ENTRENAMIENTO FINAL (refit) MAXIMIZANDO F1 EN TRAIN\n","# ---------------------------------------------------------------\n","# - GridSearchCV con m√©trica F1 (clase positiva = quiebra)\n","# - 3 modelos: \"b√°sico\" (L2 con C grande), Ridge (L2), Lasso (L1)\n","# - Tras el tuning, GridSearchCV reentrena en todo TRAIN (refit=True)\n","# ================================================================\n","\n","from sklearn.model_selection import GridSearchCV, StratifiedKFold\n","\n","grid_C_l2 = {\"C\": np.logspace(-3, 3, 7)}   # para L2 (incluye \"b√°sico\" y Ridge)\n","grid_C_l1 = {\"C\": np.logspace(-3, 2, 6)}   # para L1 (liblinear/saga)\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","grids = {\n","    \"Logit_Basico\": GridSearchCV(\n","        estimator=base_models[\"Logit_Basico\"],\n","        param_grid=grid_C_l2,\n","        scoring=\"f1\",\n","        cv=cv,\n","        n_jobs=-1,\n","        refit=True,   # reentrena con el mejor C en TODO TRAIN\n","        verbose=0\n","    ),\n","    \"Logit_Ridge\": GridSearchCV(\n","        estimator=base_models[\"Logit_Ridge\"],\n","        param_grid=grid_C_l2,\n","        scoring=\"f1\",\n","        cv=cv,\n","        n_jobs=-1,\n","        refit=True,\n","        verbose=0\n","    ),\n","    \"Logit_Lasso\": GridSearchCV(\n","        estimator=base_models[\"Logit_Lasso\"],\n","        param_grid=grid_C_l1,\n","        scoring=\"f1\",\n","        cv=cv,\n","        n_jobs=-1,\n","        refit=True,\n","        verbose=0\n","    ),\n","}\n","\n","best_models = {}\n","\n","for name, g in grids.items():\n","    g.fit(X_train, y_train)\n","    best_models[name] = g.best_estimator_\n","    print(f\"\\n{name}\")\n","    print(\"  Mejor C:   \", g.best_params_[\"C\"])\n","    print(\"  F1 (CV Œº): \", round(g.best_score_, 4))\n","\n","print(\"\\n Tuning terminado. Modelos reentrenados en TRAIN con su mejor C.\")"],"metadata":{"id":"D2utGannuWzr","executionInfo":{"status":"aborted","timestamp":1756871096267,"user_tz":300,"elapsed":0,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"OSHxnhwQ5vWY"}},{"cell_type":"code","source":["# ================================================================\n","#  PREDICCIONES EN TEST (clases y probabilidades)\n","# ================================================================\n","\n","predictions = {}\n","probabilities = {}\n","\n","for name, model in best_models.items():\n","    predictions[name] = model.predict(X_test)\n","    # Probabilidad de la clase positiva (1 = quiebra)\n","    if hasattr(model, \"predict_proba\"):\n","        probabilities[name] = model.predict_proba(X_test)[:, 1]\n","    else:\n","        probabilities[name] = model.decision_function(X_test)\n","\n","\n","\n"," # Chequeo limpio de distribuci√≥n de clases predichas\n","import numpy as np\n","for name in predictions:\n","    unique, counts = np.unique(predictions[name], return_counts=True)\n","    clean = {int(u): int(c) for u, c in zip(unique, counts)}\n","    print(f\"{name} -> distribuci√≥n de predicciones en TEST:\", clean)"],"metadata":{"id":"dSOt7Z45wKlP","executionInfo":{"status":"aborted","timestamp":1756871096286,"user_tz":300,"elapsed":18,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"YZ4_-0VTxnYD"}},{"cell_type":"markdown","source":["# Metricas de Evaluacion"],"metadata":{"id":"Cbda2eBixeI8"}},{"cell_type":"markdown","source":["Matriz de confusion"],"metadata":{"id":"xn0dQTdTxo2L"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","def plot_confusion_matrices(y_true, predictions_dict, title_prefix=\"TEST - \"):\n","    n = len(predictions_dict)\n","    n_cols = min(3, n)\n","    n_rows = (n + n_cols - 1) // n_cols\n","\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n","    axes = np.atleast_1d(axes).ravel()\n","\n","    for i, (name, y_pred) in enumerate(predictions_dict.items()):\n","        cm = confusion_matrix(y_true, y_pred)\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n","        axes[i].set_title(f\"{title_prefix}Matriz de confusi√≥n: {name}\")\n","        axes[i].set_xlabel(\"Predicci√≥n\")\n","        axes[i].set_ylabel(\"Real\")\n","\n","    for j in range(len(predictions_dict), len(axes)):\n","        axes[j].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_confusion_matrices(y_test, predictions)"],"metadata":{"id":"kYftCBYWxtEn","executionInfo":{"status":"aborted","timestamp":1756871096288,"user_tz":300,"elapsed":144446,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Curvas ROC"],"metadata":{"id":"Yp2TK50dx1TF"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve, roc_auc_score\n","\n","def plot_roc_curves(y_true, probabilities_dict, title=\"Curvas ROC (Test)\"):\n","    plt.figure(figsize=(8,6))\n","    best_auc, best_name = 0.0, None\n","\n","    for name, probs in probabilities_dict.items():\n","        fpr, tpr, _ = roc_curve(y_true, probs)\n","        auc = roc_auc_score(y_true, probs)\n","        plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n","        if auc > best_auc:\n","            best_auc, best_name = auc, name\n","\n","    plt.plot([0,1],[0,1], 'k--', label=\"Random\")\n","    plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n","    plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n","    plt.title(title + (f\" | Mejor: {best_name}\" if best_name else \"\"))\n","    plt.legend()\n","    plt.grid(alpha=0.3)\n","    plt.show()\n","\n","plot_roc_curves(y_test, probabilities)"],"metadata":{"id":"FqWuu4qpxxti","executionInfo":{"status":"aborted","timestamp":1756871096288,"user_tz":300,"elapsed":144446,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tabla comparativa de m√©tricas"],"metadata":{"id":"6dvGlU8AyAxw"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(\"\\nM√©tricas en TEST (Modelos con mejor C por F1)\")\n","print(\"=\"*76)\n","print(f\"{'Modelo':15s} {'Accuracy':>10s} {'Precision':>10s} {'Recall':>10s} {'F1-Score':>10s} {'AUC-ROC':>10s}\")\n","print(\"-\"*76)\n","\n","for name in predictions.keys():\n","    y_pred = predictions[name]\n","    probs  = probabilities[name]\n","    rep = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n","    acc  = rep['accuracy']\n","    prec = rep['1']['precision']\n","    rec  = rep['1']['recall']\n","    f1   = rep['1']['f1-score']\n","    auc  = roc_auc_score(y_test, probs)\n","    print(f\"{name:15s} {acc:10.3f} {prec:10.3f} {rec:10.3f} {f1:10.3f} {auc:10.3f}\")"],"metadata":{"id":"j39EF2WOyC_R","executionInfo":{"status":"aborted","timestamp":1756871096288,"user_tz":300,"elapsed":144445,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Validacion cruzada"],"metadata":{"id":"6QWlmXxL5xxE"}},{"cell_type":"code","source":["# ============================================================\n","# 9) Validaci√≥n cruzada (K-Fold y Estratificada) + Visuales\n","#     - Imprime valores por fold, promedio y desviaci√≥n\n","#     - Boxplots con \"zoom\" en eje Y + puntos por fold\n","# ============================================================\n","\n","from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","import pandas as pd\n","\n","# --------- Configuraci√≥n ----------\n","CV_K = 5\n","RANDOM_STATE = 42\n","SCORING = \"f1\"  # Para quiebra/desbalance conviene F1\n","\n","# IMPORTANT: usa tu diccionario de modelos aqu√≠\n","# Ejemplo:\n","# best_models = {\n","#     \"Logit_B√°sico\": modelo_logit,\n","#     \"Logit_Ridge\":  modelo_ridge,\n","#     \"Logit_Lasso\":  modelo_lasso,\n","# }\n","\n","models_dict = best_models  # <- ajusta si tu variable se llama distinto\n","\n","# --------- Funci√≥n auxiliar para CV ----------\n","def cv_scores_report(estimator, X, y, k=5, random_state=42, scoring=\"f1\"):\n","    # K-Fold normal\n","    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n","    scores_k = cross_val_score(estimator, X, y, cv=kf, scoring=scoring, n_jobs=-1)\n","    # K-Fold estratificado\n","    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n","    scores_s = cross_val_score(estimator, X, y, cv=skf, scoring=scoring, n_jobs=-1)\n","    return scores_k, scores_s\n","\n","# --------- Ejecutar CV y almacenar resultados ----------\n","results_k = {}      # {modelo: array de F1 por fold (K-Fold)}\n","results_skf = {}    # {modelo: array de F1 por fold (Estratificado)}\n","\n","print(\"\\nüìä Resumen de Validaci√≥n Cruzada (F1):\")\n","for name, est in models_dict.items():\n","    s_k, s_s = cv_scores_report(est, X_train, y_train, k=CV_K,\n","                                random_state=RANDOM_STATE, scoring=SCORING)\n","    results_k[name] = s_k\n","    results_skf[name] = s_s\n","\n","    print(f\"\\nüîπ Validaci√≥n K-Fold para {name}\")\n","    print(f\"F1 por fold: {np.round(s_k, 6).tolist()}\")\n","    print(f\"Promedio: {np.mean(s_k):.6f}  |  Desviaci√≥n: {np.std(s_k):.6f}\")\n","\n","    print(f\"üîπ Validaci√≥n Estratificada para {name}\")\n","    print(f\"F1 por fold: {np.round(s_s, 6).tolist()}\")\n","    print(f\"Promedio: {np.mean(s_s):.6f}  |  Desviaci√≥n: {np.std(s_s):.6f}\")\n","\n","# --------- Tabla resumen (promedios/desviaciones) ----------\n","summary_rows = []\n","for name in models_dict.keys():\n","    row = {\n","        \"Modelo\": name,\n","        \"KFold_mean\": np.mean(results_k[name]),\n","        \"KFold_std\":  np.std(results_k[name]),\n","        \"Strat_mean\": np.mean(results_skf[name]),\n","        \"Strat_std\":  np.std(results_skf[name]),\n","    }\n","    summary_rows.append(row)\n","\n","cv_summary_df = pd.DataFrame(summary_rows).sort_values(by=\"Strat_mean\", ascending=False)\n","print(\"\\n\\nüìã Tabla resumen (ordenada por F1 estratificado):\\n\")\n","print(cv_summary_df.to_string(index=False, float_format=\"%.6f\"))\n","\n","# --------- Gr√°ficas (boxplot + puntos por fold) ----------\n","def plot_cv_boxplots(data_dict, title, ylim=(0.0, 0.03), percent=True):\n","    labels = list(data_dict.keys())\n","    data = [data_dict[k] for k in labels]\n","\n","    fig, ax = plt.subplots(figsize=(10, 5), dpi=140)\n","    bp = ax.boxplot(data, tick_labels=labels, showmeans=True, meanline=True)\n","\n","    # Puntos de cada fold con jitter para verlos\n","    for i, k in enumerate(labels, start=1):\n","        yvals = np.array(data_dict[k])\n","        xvals = np.random.normal(loc=i, scale=0.03, size=len(yvals))\n","        ax.scatter(xvals, yvals, alpha=0.85)\n","\n","    # Zoom del eje Y para que no se vea \"aplastado\"\n","    if ylim is not None:\n","        ax.set_ylim(*ylim)\n","\n","    # Formato de eje Y\n","    if percent:\n","        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))  # valores [0,1] a %\n","        ax.set_ylabel(\"F1-Score (%)\")\n","    else:\n","        ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.4f'))\n","        ax.set_ylabel(\"F1-Score\")\n","\n","    ax.set_title(title)\n","    ax.grid(alpha=0.25)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Ajusta el rango seg√∫n tus valores t√≠picos (p.ej., 0.00‚Äì0.03 = 0%‚Äì3%)\n","plot_cv_boxplots(results_k,   \"Validaci√≥n Cruzada K-Fold (F1-Score)\", ylim=(0.00, 0.03), percent=True)\n","plot_cv_boxplots(results_skf, \"Validaci√≥n Cruzada Estratificada (F1-Score)\", ylim=(0.00, 0.03), percent=True)\n","\n"],"metadata":{"id":"5M4p-Z4T5znc","executionInfo":{"status":"aborted","timestamp":1756871096289,"user_tz":300,"elapsed":144445,"user":{"displayName":"Samuel Suarez","userId":"03892127148973121800"}}},"execution_count":null,"outputs":[]}]}